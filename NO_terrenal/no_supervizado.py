# aprendizaje_no_supervisado.py
import numpy as np
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering
from sklearn.decomposition import PCA, LatentDirichletAllocation
from sklearn.metrics import silhouette_score, calinski_harabasz_score
import matplotlib.pyplot as plt
import seaborn as sns
from textblob import TextBlob
import re
import json
import pickle
from datetime import datetime
from collections import Counter
from wordcloud import WordCloud
import warnings
warnings.filterwarnings('ignore')

class AprendizajeNoSupervisadoDBZ:
    def __init__(self):
        # Dataset de reseÃ±as de Dragon Ball Z (SIN etiquetas para simular no supervisado)
        self.reseÃ±as_dbz = [
            # ReseÃ±as positivas (15)
            "Dragon Ball Z es increÃ­ble, las peleas son Ã©picas y los personajes estÃ¡n geniales",
            "Me encanta la transformaciÃ³n de Goku en Super Saiyajin, es lo mejor del anime",
            "Las batallas de DBZ son espectaculares, especialmente contra Cell y Majin Buu",
            "Vegeta es un personaje fantÃ¡stico con mucho desarrollo a lo largo de la serie",
            "La saga de Freezer es obra maestra, tensiÃ³n y acciÃ³n en cada episodio",
            "Gohan siendo el hÃ©roe contra Cell fue un momento perfecto e inolvidable",
            "La mÃºsica de Dragon Ball Z es excelente y hace las peleas mÃ¡s emocionantes",
            "Los momentos emotivos como el sacrificio de Vegeta son conmovedores",
            "Las transformaciones son increÃ­bles y cada una mÃ¡s poderosa que la anterior",
            "Dragon Ball Z marcÃ³ mi infancia, es una serie que nunca olvidarÃ©",
            "Excelente desarrollo de personajes y narrativa Ã©pica",
            "Los poderes y tÃ©cnicas especiales son geniales y creativos",
            "Las peleas tienen una coreografÃ­a perfecta y emocionante",
            "Frieza es uno de los mejores villanos del anime",
            "El torneo de Cell fue espectacular y lleno de sorpresas",
            
            # ReseÃ±as negativas (20)
            "Dragon Ball Z tiene demasiado relleno y episodios que no aportan nada",
            "Los gritos constantes y el poder creep arruinan la experiencia",
            "GT fue un desastre total comparado con la calidad de Z",
            "Los diÃ¡logos durante las peleas son repetitivos y aburridos",
            "Demasiados episodios dedicados solo a cargar ki, es frustrante",
            "La saga de Buu se alargÃ³ innecesariamente y perdiÃ³ el ritmo",
            "Los personajes secundarios fueron olvidados despuÃ©s de Z",
            "Las peleas se volvieron predecibles: gritar mÃ¡s fuerte para ganar",
            "La animaciÃ³n tiene inconsistencias molestas en varios episodios",
            "El final de Dragon Ball Z fue decepcionante despuÃ©s de tanto hype",
            "Muy lento, muchos episodios sin acciÃ³n real",
            "Los personajes femeninos estÃ¡n muy mal desarrollados",
            "Las transformaciones perdieron sentido despuÃ©s de Super Saiyajin",
            "Demasiado enfoque en el poder y poco en la historia",
            "Los villanos despuÃ©s de Frieza son aburridos y genÃ©ricos",
            "La serie se volviÃ³ muy comercial y perdiÃ³ su esencia",
            "Muchos plot holes y inconsistencias en la historia",
            "Los combates son demasiado largos y tediosos",
            "Falta de desarrollo para personajes no Saiyajin",
            "El poder scaling no tiene sentido despuÃ©s de Namek"
        ]
        
        # Etiquetas reales (solo para evaluaciÃ³n, NO se usan en entrenamiento)
        self.etiquetas_reales = [1]*15 + [0]*20  # 15 positivas, 20 negativas = 35 total = 35 total
        
        self.vectorizer = TfidfVectorizer(max_features=800, ngram_range=(1, 2), min_df=1)
        self.modelo_clustering = None
        self.clusters = None
        self.X_vectorizado = None
        self.comentarios_analizados = []
        self.interpretacion_clusters = {}
        
    def preprocesar_texto(self, texto):
        """Preprocesa el texto eliminando caracteres especiales y normalizando"""
        texto = texto.lower()
        texto = re.sub(r'[^\w\sÃ¡Ã©Ã­Ã³ÃºÃ±Ã¼]', '', texto)  # Mantener acentos espaÃ±oles
        texto = re.sub(r'\s+', ' ', texto).strip()
        return texto
    
    def entrenar_clustering(self):
        """Entrena diferentes modelos de clustering"""
        print("ğŸ” === ENTRENAMIENTO APRENDIZAJE NO SUPERVISADO DBZ === ğŸ”")
        print("=" * 65)
        
        # Preprocesar textos
        textos_procesados = [self.preprocesar_texto(texto) for texto in self.reseÃ±as_dbz]
        
        print(f"ğŸ“Š Dataset: {len(textos_procesados)} reseÃ±as (SIN etiquetas)")
        
        # VectorizaciÃ³n
        print("\nğŸ”„ Vectorizando texto...")
        self.X_vectorizado = self.vectorizer.fit_transform(textos_procesados)
        print(f"   - CaracterÃ­sticas extraÃ­das: {self.X_vectorizado.shape[1]}")
        
        # Probar diferentes algoritmos de clustering
        algoritmos = {
            'K-Means': KMeans(n_clusters=2, random_state=42, n_init=10),
            'K-Means (3 clusters)': KMeans(n_clusters=3, random_state=42, n_init=10),
            'DBSCAN': DBSCAN(eps=0.5, min_samples=2),
            'Clustering JerÃ¡rquico': AgglomerativeClustering(n_clusters=2)
        }
        
        resultados = {}
        
        print("\nğŸ”¬ Probando algoritmos de clustering...")
        print("-" * 50)
        
        for nombre, algoritmo in algoritmos.items():
            print(f"\nğŸ§ª Aplicando {nombre}...")
            
            # Aplicar clustering
            if nombre == 'DBSCAN' or 'JerÃ¡rquico' in nombre:
                # DBSCAN y Clustering JerÃ¡rquico necesitan datos densos
                X_denso = self.X_vectorizado.toarray()
                clusters = algoritmo.fit_predict(X_denso)
            else:
                # K-Means puede trabajar con matrices dispersas
                clusters = algoritmo.fit_predict(self.X_vectorizado)
            
            # Calcular mÃ©tricas
            n_clusters = len(set(clusters)) - (1 if -1 in clusters else 0)
            n_ruido = list(clusters).count(-1)
            
            # Silhouette score (solo si hay mÃ¡s de 1 cluster)
            if n_clusters > 1 and n_clusters < len(textos_procesados):
                if nombre == 'DBSCAN' or 'JerÃ¡rquico' in nombre:
                    # Ya tenemos X_denso para estos algoritmos
                    silhouette = silhouette_score(X_denso, clusters) if n_clusters > 1 else -1
                else:
                    # Para K-Means convertimos a denso
                    silhouette = silhouette_score(self.X_vectorizado.toarray(), clusters)
            else:
                silhouette = -1
            
            resultados[nombre] = {
                'algoritmo': algoritmo,
                'clusters': clusters,
                'n_clusters': n_clusters,
                'n_ruido': n_ruido,
                'silhouette_score': silhouette
            }
            
            print(f"   âœ… Clusters encontrados: {n_clusters}")
            if n_ruido > 0:
                print(f"   âš ï¸ Puntos de ruido: {n_ruido}")
            if silhouette > -1:
                print(f"   ğŸ“ˆ Silhouette Score: {silhouette:.3f}")
            
            # Mostrar distribuciÃ³n de clusters
            cluster_counts = Counter(clusters)
            print(f"   ğŸ“Š DistribuciÃ³n: {dict(cluster_counts)}")
        
        # Seleccionar mejor algoritmo (K-Means con 2 clusters por defecto)
        self.modelo_clustering = algoritmos['K-Means']
        self.clusters = resultados['K-Means']['clusters']
        
        print(f"\nğŸ† Algoritmo seleccionado: K-Means (2 clusters)")
        print(f"ğŸ¯ Silhouette Score: {resultados['K-Means']['silhouette_score']:.3f}")
        
        # Interpretar clusters
        self._interpretar_clusters()
        
        # Visualizar resultados
        self._visualizar_clusters()
        
        # Guardar modelo
        self._guardar_modelo()
        
        return resultados
    
    def _interpretar_clusters(self):
        """Interpreta el significado de cada cluster usando anÃ¡lisis de palabras"""
        print(f"\nğŸ§  INTERPRETACIÃ“N DE CLUSTERS")
        print("=" * 40)
        
        textos_procesados = [self.preprocesar_texto(texto) for texto in self.reseÃ±as_dbz]
        
        for cluster_id in set(self.clusters):
            print(f"\nğŸ” CLUSTER {cluster_id}:")
            
            # Obtener textos del cluster
            indices_cluster = [i for i, c in enumerate(self.clusters) if c == cluster_id]
            textos_cluster = [textos_procesados[i] for i in indices_cluster]
            
            print(f"   ğŸ“Š Total de reseÃ±as: {len(textos_cluster)}")
            
            # Analizar palabras mÃ¡s frecuentes
            texto_completo = ' '.join(textos_cluster)
            palabras = texto_completo.split()
            palabras_frecuentes = Counter(palabras).most_common(10)
            
            print(f"   ğŸ”¤ Palabras mÃ¡s frecuentes:")
            for palabra, freq in palabras_frecuentes[:5]:
                print(f"      - {palabra}: {freq}")
            
            # AnÃ¡lisis de sentimiento promedio con TextBlob
            polaridades = []
            for texto_original in [self.reseÃ±as_dbz[i] for i in indices_cluster]:
                blob = TextBlob(texto_original)
                polaridades.append(blob.sentiment.polarity)
            
            polaridad_promedio = np.mean(polaridades)
            
            # InterpretaciÃ³n del cluster
            if polaridad_promedio > 0.05:
                interpretacion = "ğŸ˜Š Positivo"
                sentimiento = "positivo"
            elif polaridad_promedio < -0.05:
                interpretacion = "ğŸ˜ Negativo"
                sentimiento = "negativo"
            else:
                interpretacion = "ğŸ˜ Neutro"
                sentimiento = "neutro"
            
            self.interpretacion_clusters[cluster_id] = sentimiento
            
            print(f"   ğŸ­ Polaridad promedio: {polaridad_promedio:.3f}")
            print(f"   ğŸ·ï¸ InterpretaciÃ³n: {interpretacion}")
            
            # Mostrar ejemplos representativos
            print(f"   ğŸ“ Ejemplos de reseÃ±as:")
            for i, idx in enumerate(indices_cluster[:3]):
                print(f"      {i+1}. {self.reseÃ±as_dbz[idx][:60]}...")
    
    def _visualizar_clusters(self):
        """Visualiza los clusters usando PCA y grÃ¡ficos"""
        print(f"\nğŸ“Š VISUALIZACIÃ“N DE CLUSTERS")
        print("=" * 35)
        
        # PCA para reducir dimensionalidad
        pca = PCA(n_components=2, random_state=42)
        X_pca = pca.fit_transform(self.X_vectorizado.toarray())
        
        # Crear visualizaciÃ³n
        plt.figure(figsize=(15, 5))
        
        # Subplot 1: Clusters predichos
        plt.subplot(1, 3, 1)
        scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=self.clusters, 
                            cmap='viridis', alpha=0.7, s=100)
        plt.title('ğŸ” Clusters Descubiertos\n(Aprendizaje No Supervisado)', fontsize=12)
        plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} varianza)')
        plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} varianza)')
        plt.colorbar(scatter, label='Cluster ID')
        plt.grid(True, alpha=0.3)
        
        # Subplot 2: Sentimientos reales (para comparaciÃ³n)
        plt.subplot(1, 3, 2)
        colores_reales = ['red' if label == 0 else 'green' for label in self.etiquetas_reales]
        scatter2 = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=colores_reales, 
                             alpha=0.7, s=100)
        plt.title('ğŸ¯ Sentimientos Reales\n(Solo para comparaciÃ³n)', fontsize=12)
        plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} varianza)')
        plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} varianza)')
        plt.grid(True, alpha=0.3)
        
        # AÃ±adir leyenda manual
        from matplotlib.patches import Patch
        legend_elements = [Patch(facecolor='red', label='ğŸ˜ Negativo'),
                          Patch(facecolor='green', label='ğŸ˜Š Positivo')]
        plt.legend(handles=legend_elements)
        
        # Subplot 3: ComparaciÃ³n de precisiÃ³n
        plt.subplot(1, 3, 3)
        self._calcular_precision_clusters()
        
        plt.tight_layout()
        plt.savefig('clusters_dbz_no_supervisado.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        print("ğŸ“ˆ GrÃ¡fico guardado como 'clusters_dbz_no_supervisado.png'")
    
    def _calcular_precision_clusters(self):
        """Calcula quÃ© tan bien los clusters capturan los sentimientos"""
        # Crear matriz de confusiÃ³n entre clusters y sentimientos reales
        cluster_0_real = [self.etiquetas_reales[i] for i in range(len(self.clusters)) if self.clusters[i] == 0]
        cluster_1_real = [self.etiquetas_reales[i] for i in range(len(self.clusters)) if self.clusters[i] == 1]
        
        # Calcular pureza de cada cluster
        pureza_cluster_0 = max(cluster_0_real.count(0), cluster_0_real.count(1)) / len(cluster_0_real) if cluster_0_real else 0
        pureza_cluster_1 = max(cluster_1_real.count(0), cluster_1_real.count(1)) / len(cluster_1_real) if cluster_1_real else 0
        
        clusters = ['Cluster 0', 'Cluster 1']
        purezas = [pureza_cluster_0, pureza_cluster_1]
        colores = ['lightcoral', 'lightgreen']
        
        bars = plt.bar(clusters, purezas, color=colores, alpha=0.7, edgecolor='black')
        plt.title('ğŸ¯ Pureza de Clusters\n(% de elementos dominantes)', fontsize=12)
        plt.ylabel('Pureza (%)')
        plt.ylim(0, 1)
        
        # AÃ±adir valores en las barras
        for bar, pureza in zip(bars, purezas):
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, 
                    f'{pureza:.1%}', ha='center', va='bottom', fontweight='bold')
        
        plt.grid(True, alpha=0.3, axis='y')
    
    def predecir_cluster(self, comentario):
        """Predice el cluster de un nuevo comentario"""
        if self.modelo_clustering is None:
            return {"error": "Modelo no entrenado. Ejecuta entrenar_clustering() primero."}
        
        # Preprocesar comentario
        comentario_limpio = self.preprocesar_texto(comentario)
        
        # Vectorizar
        X_comentario = self.vectorizer.transform([comentario_limpio])
        
        # Predicir cluster
        cluster_predicho = self.modelo_clustering.predict(X_comentario)[0]
        
        # Calcular distancia al centroide
        centroide = self.modelo_clustering.cluster_centers_[cluster_predicho]
        distancia = np.linalg.norm(X_comentario.toarray() - centroide)
        
        # AnÃ¡lisis adicional con TextBlob
        blob = TextBlob(comentario)
        polaridad_textblob = blob.sentiment.polarity
        
        # Interpretar resultado
        sentimiento_interpretado = self.interpretacion_clusters.get(cluster_predicho, "desconocido")
        
        resultado = {
            'comentario_original': comentario,
            'comentario_procesado': comentario_limpio,
            'cluster_predicho': int(cluster_predicho),
            'sentimiento_interpretado': sentimiento_interpretado,
            'distancia_centroide': float(distancia),
            'confianza': max(0, 1 - (distancia / 2)),  # Confianza basada en distancia
            'textblob_polaridad': polaridad_textblob,
            'textblob_sentimiento': self._interpretar_textblob(polaridad_textblob),
            'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        
        return resultado
    
    def _interpretar_textblob(self, polaridad):
        """Interpreta la polaridad de TextBlob"""
        if polaridad > 0.1:
            return "Positivo"
        elif polaridad < -0.1:
            return "Negativo"
        else:
            return "Neutro"
    
    def evaluar_comentario_interactivo(self, comentario):
        """EvalÃºa un comentario y muestra resultado formateado"""
        resultado = self.predecir_cluster(comentario)
        
        if 'error' in resultado:
            print(f"âŒ Error: {resultado['error']}")
            return
        
        print(f"\nğŸ” ANÃLISIS NO SUPERVISADO - DRAGON BALL Z ğŸ”")
        print("=" * 55)
        print(f"ğŸ’¬ Comentario: '{comentario}'")
        print("-" * 55)
        
        # Resultado principal
        cluster_emoji = "ğŸ˜Š" if resultado['sentimiento_interpretado'] == 'positivo' else "ğŸ˜" if resultado['sentimiento_interpretado'] == 'negativo' else "ğŸ˜"
        print(f"{cluster_emoji} CLUSTER ASIGNADO: {resultado['cluster_predicho']}")
        print(f"ğŸ­ SENTIMIENTO INTERPRETADO: {resultado['sentimiento_interpretado'].upper()}")
        print(f"ğŸ¯ Confianza: {resultado['confianza']:.1%}")
        print(f"ğŸ“ Distancia al centroide: {resultado['distancia_centroide']:.3f}")
        
        # AnÃ¡lisis TextBlob
        tb_emoji = "ğŸ˜Š" if resultado['textblob_sentimiento'] == 'Positivo' else "ğŸ˜" if resultado['textblob_sentimiento'] == 'Negativo' else "ğŸ˜"
        print(f"\nğŸ“ TextBlob: {tb_emoji} {resultado['textblob_sentimiento']} (Polaridad: {resultado['textblob_polaridad']:.3f})")
        
        # Consistencia entre mÃ©todos
        consistente = (
            (resultado['sentimiento_interpretado'] == 'positivo' and resultado['textblob_sentimiento'] == 'Positivo') or
            (resultado['sentimiento_interpretado'] == 'negativo' and resultado['textblob_sentimiento'] == 'Negativo')
        )
        
        consistency_emoji = "âœ…" if consistente else "âš ï¸"
        print(f"{consistency_emoji} Consistencia entre mÃ©todos: {'SÃ' if consistente else 'NO'}")
        
        # Guardar comentario
        self.comentarios_analizados.append(resultado)
        self._guardar_comentarios()
        
        print(f"ğŸ’¾ Comentario guardado correctamente!")
        print("=" * 55)
        
        return resultado
    
    def generar_nube_palabras(self):
        """Genera nubes de palabras para cada cluster"""
        try:
            print("\nâ˜ï¸ GENERANDO NUBES DE PALABRAS POR CLUSTER...")
            
            textos_procesados = [self.preprocesar_texto(texto) for texto in self.reseÃ±as_dbz]
            
            plt.figure(figsize=(15, 6))
            
            for cluster_id in set(self.clusters):
                indices_cluster = [i for i, c in enumerate(self.clusters) if c == cluster_id]
                textos_cluster = [textos_procesados[i] for i in indices_cluster]
                texto_completo = ' '.join(textos_cluster)
                
                # Crear nube de palabras
                wordcloud = WordCloud(width=400, height=300, 
                                    background_color='white',
                                    colormap='viridis' if cluster_id == 0 else 'plasma',
                                    max_words=50).generate(texto_completo)
                
                plt.subplot(1, 2, cluster_id + 1)
                plt.imshow(wordcloud, interpolation='bilinear')
                plt.title(f'Cluster {cluster_id}\n({self.interpretacion_clusters.get(cluster_id, "desconocido")})')
                plt.axis('off')
            
            plt.tight_layout()
            plt.savefig('wordclouds_clusters_dbz.png', dpi=300, bbox_inches='tight')
            plt.show()
            print("â˜ï¸ Nubes de palabras guardadas como 'wordclouds_clusters_dbz.png'")
            
        except ImportError:
            print("âš ï¸ WordCloud no estÃ¡ instalado. Instala con: pip install wordcloud")
        except Exception as e:
            print(f"âŒ Error generando nubes de palabras: {e}")
    
    def analizar_topicos(self, n_topicos=3):
        """Realiza anÃ¡lisis de tÃ³picos usando LDA"""
        print(f"\nğŸ“š ANÃLISIS DE TÃ“PICOS (LDA)")
        print("=" * 35)
        
        # Usar CountVectorizer para LDA
        vectorizer_lda = CountVectorizer(max_features=100, min_df=1, max_df=0.8)
        textos_procesados = [self.preprocesar_texto(texto) for texto in self.reseÃ±as_dbz]
        X_counts = vectorizer_lda.fit_transform(textos_procesados)
        
        # Aplicar LDA
        lda = LatentDirichletAllocation(n_components=n_topicos, random_state=42, max_iter=100)
        lda.fit(X_counts)
        
        # Mostrar tÃ³picos
        feature_names = vectorizer_lda.get_feature_names_out()
        
        for topic_idx, topic in enumerate(lda.components_):
            top_words_idx = topic.argsort()[-10:][::-1]
            top_words = [feature_names[i] for i in top_words_idx]
            print(f"\nğŸ¯ TÃ³pico {topic_idx + 1}:")
            print(f"   Palabras clave: {', '.join(top_words[:5])}")
            
        return lda, vectorizer_lda
    
    def mostrar_estadisticas(self):
        """Muestra estadÃ­sticas de los comentarios analizados"""
        if not self.comentarios_analizados:
            print("ğŸ“Š No hay comentarios analizados aÃºn.")
            return
        
        print(f"\nğŸ“Š ESTADÃSTICAS DE ANÃLISIS NO SUPERVISADO")
        print("=" * 50)
        print(f"Total de comentarios analizados: {len(self.comentarios_analizados)}")
        
        # DistribuciÃ³n por clusters
        clusters_asignados = [c['cluster_predicho'] for c in self.comentarios_analizados]
        cluster_counts = Counter(clusters_asignados)
        
        for cluster_id, count in cluster_counts.items():
            sentimiento = self.interpretacion_clusters.get(cluster_id, "desconocido")
            emoji = "ğŸ˜Š" if sentimiento == 'positivo' else "ğŸ˜" if sentimiento == 'negativo' else "ğŸ˜"
            porcentaje = count / len(self.comentarios_analizados) * 100
            print(f"{emoji} Cluster {cluster_id} ({sentimiento}): {count} ({porcentaje:.1f}%)")
        
        # Confianza promedio
        confianza_promedio = np.mean([c['confianza'] for c in self.comentarios_analizados])
        print(f"ğŸ¯ Confianza promedio: {confianza_promedio:.1%}")
        
        # Distancia promedio
        distancia_promedio = np.mean([c['distancia_centroide'] for c in self.comentarios_analizados])
        print(f"ğŸ“ Distancia promedio al centroide: {distancia_promedio:.3f}")
        
        print(f"\nğŸ“ Ãšltimos 5 comentarios:")
        for comentario in self.comentarios_analizados[-5:]:
            cluster_id = comentario['cluster_predicho']
            sentimiento = self.interpretacion_clusters.get(cluster_id, "desconocido")
            emoji = "ğŸ˜Š" if sentimiento == 'positivo' else "ğŸ˜" if sentimiento == 'negativo' else "ğŸ˜"
            print(f"   {emoji} {comentario['comentario_original'][:40]}... -> Cluster {cluster_id}")
    
    def _guardar_modelo(self):
        """Guarda el modelo entrenado"""
        try:
            with open('modelo_no_supervisado_dbz.pkl', 'wb') as f:
                pickle.dump({
                    'modelo_clustering': self.modelo_clustering,
                    'vectorizer': self.vectorizer,
                    'interpretacion_clusters': self.interpretacion_clusters,
                    'clusters_entrenamiento': self.clusters
                }, f)
            print("ğŸ’¾ Modelo no supervisado guardado en 'modelo_no_supervisado_dbz.pkl'")
        except Exception as e:
            print(f"âŒ Error guardando modelo: {e}")
    
    def _cargar_modelo(self):
        """Carga el modelo previamente entrenado"""
        try:
            with open('modelo_no_supervisado_dbz.pkl', 'rb') as f:
                datos = pickle.load(f)
                self.modelo_clustering = datos['modelo_clustering']
                self.vectorizer = datos['vectorizer']
                self.interpretacion_clusters = datos['interpretacion_clusters']
                self.clusters = datos['clusters_entrenamiento']
                print("âœ… Modelo no supervisado cargado correctamente")
                return True
        except FileNotFoundError:
            print("âš ï¸ No se encontrÃ³ modelo guardado. Entrena primero.")
            return False
        except Exception as e:
            print(f"âŒ Error cargando modelo: {e}")
            return False
    
    def _guardar_comentarios(self):
        """Guarda los comentarios analizados"""
        try:
            with open('comentarios_no_supervisado_dbz.json', 'w', encoding='utf-8') as f:
                json.dump(self.comentarios_analizados, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"âŒ Error guardando comentarios: {e}")
    
    def probar_ejemplos(self):
        """Prueba el modelo con comentarios de ejemplo"""
        ejemplos = [
            "Goku es el mejor hÃ©roe de todos los tiempos, increÃ­ble",
            "Dragon Ball Z es muy aburrido y lento",
            "Las transformaciones Super Saiyajin son espectaculares",
            "Demasiados episodios de relleno sin sentido",
            "Vegeta tiene el mejor desarrollo de personaje"
        ]
        
        print("\nğŸ§ª PRUEBAS CON EJEMPLOS:")
        print("=" * 40)
        
        for comentario in ejemplos:
            resultado = self.predecir_cluster(comentario)
            cluster_id = resultado['cluster_predicho']
            sentimiento = self.interpretacion_clusters.get(cluster_id, "desconocido")
            emoji = "ğŸ˜Š" if sentimiento == 'positivo' else "ğŸ˜" if sentimiento == 'negativo' else "ğŸ˜"
            print(f"{emoji} '{comentario[:40]}...' -> Cluster {cluster_id} ({sentimiento})")

def main():
    """FunciÃ³n principal"""
    print("ğŸ” SISTEMA DE ANÃLISIS NO SUPERVISADO - DRAGON BALL Z ğŸ”")
    print("=" * 65)
    
    analizador = AprendizajeNoSupervisadoDBZ()
    
    # Intentar cargar modelo existente
    if not analizador._cargar_modelo():
        print("\nğŸ”¬ Entrenando modelo de clustering...")
        analizador.entrenar_clustering()
        
        # AnÃ¡lisis adicionales
        analizador.generar_nube_palabras()
        analizador.analizar_topicos()
        analizador.probar_ejemplos()
    
    print("\nğŸ® Â¡Sistema listo! Comandos disponibles:")
    print("   - Escribe un comentario para analizarlo")
    print("   - 'stats' para ver estadÃ­sticas")
    print("   - 'ejemplos' para ver ejemplos de prueba")
    print("   - 'topicos' para anÃ¡lisis de tÃ³picos")
    print("   - 'nubes' para generar nubes de palabras")
    print("   - 'reentrenar' para entrenar de nuevo")
    print("   - 'salir' para terminar")
    print("=" * 65)
    
    while True:
        comando = input("\nğŸ’­ Tu comentario sobre DBZ (o comando): ").strip()
        
        if comando.lower() == 'salir':
            print("Â¡Hasta la vista! ğŸ”âœ¨")
            break
        elif comando.lower() == 'stats':
            analizador.mostrar_estadisticas()
        elif comando.lower() == 'ejemplos':
            analizador.probar_ejemplos()
        elif comando.lower() == 'topicos':
            analizador.analizar_topicos()
        elif comando.lower() == 'nubes':
            analizador.generar_nube_palabras()
        elif comando.lower() == 'reentrenar':
            print("ğŸ”„ Reentrenando modelo...")
            analizador.entrenar_clustering()
            analizador.generar_nube_palabras()
            analizador.analizar_topicos()
        elif comando:
            analizador.evaluar_comentario_interactivo(comando)
        else:
            print("âš ï¸ Por favor escribe un comentario vÃ¡lido.")

if __name__ == "__main__":
    # Verificar dependencias
    try:
        import wordcloud
    except ImportError:
        print("ğŸ“¦ WordCloud no encontrado. Instala con: pip install wordcloud")
    
    try:
        import textblob
    except ImportError:
        print("ğŸ“¦ Instalando TextBlob...")
        import subprocess
        subprocess.check_call(["pip", "install", "textblob"])
    
    main()